{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mlp",
      "provenance": [],
      "authorship_tag": "ABX9TyM/9zEyUT6V5futPtvlCJcG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mahsaghaderan99/MLP/blob/cross-validation/mlp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CyK4A_cco_WC"
      },
      "source": [
        "*Deep* MLP project"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pI1xwS3FuFq-"
      },
      "source": [
        "def plotter(img_list, r, w, gray, wr, hr, fig_name = None):\n",
        "    '''\n",
        "    Plots images' list with its' caption and saves result image if you want.\n",
        "\n",
        "    Parameters:\n",
        "        img_list (list): The list of tuples of image and its' caption.\n",
        "        r (int): The number of row(s).\n",
        "        w (int): The number of colunm(s).\n",
        "        gray (bool): The flag for plotting images in grayscale mode.\n",
        "        wr (int): The width of one figure.\n",
        "        hr (int): The height of one figure.\n",
        "        fig_name (str): The name of the image of the plot. if not set this parameter the plot doesn't save.\n",
        "    '''\n",
        "    \n",
        "    plt.rcParams['figure.figsize'] = (wr, hr)\n",
        "    for i in range(len(img_list)):\n",
        "        plt.subplot(r, w, i + 1)\n",
        "        if img_list[i][2] == 'img':\n",
        "            if gray:\n",
        "                plt.imshow(img_list[i][0], cmap = 'gray')\n",
        "            else:\n",
        "                plt.imshow(img_list[i][0])\n",
        "            plt.xticks([])\n",
        "            plt.yticks([])\n",
        "        elif img_list[i][2] == 'hist':\n",
        "            plt.bar(np.arange(len(img_list[i][0])), img_list[i][0], color = 'c')\n",
        "        else:\n",
        "            raise Exception(\"Only image or histogram. Use third parameter of tuples in img_list and set it to img or hist.\")\n",
        "        plt.title(img_list[i][1])\n",
        "    if fig_name is not None:\n",
        "        plt.savefig(fig_name + '.png')\n",
        "    plt.show()"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PjXUnWd6YBZ2"
      },
      "source": [
        "#PART4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZWxh5qeYELz"
      },
      "source": [
        "##Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KEoXOhINYBM0"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "import tensorflow as tf\n",
        "from os import path\n",
        "import cv2\n",
        "from skimage.util import random_noise\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from scipy import spatial"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ttuM4LyuaBN3"
      },
      "source": [
        "## load dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y2DtliMeaBN5"
      },
      "source": [
        "load mnist dataset "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8SXWA4UaBN6"
      },
      "source": [
        "path = f\"{getcwd()}/mnist.npz\""
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FASQKRhSaBN-"
      },
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data(path=path)\n",
        "training_images = training_images.reshape(60000,28,28)\n",
        "test_images = test_images.reshape(10000,28,28)"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8meLdvI5aBOB",
        "outputId": "82693bb6-2a77-440b-9bde-46d1f2acb610",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "m, n = training_images[0].shape[0], training_images[0].shape[1]\n",
        "print('The image is ({0}*{1})'.format(m,n))"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The image is (28*28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v4iiZwLNaHjE"
      },
      "source": [
        "##Preprocess Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZ8iP4sMaHjI"
      },
      "source": [
        "Normalize images --> map value into (0,1)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDH2rkwIaHjL"
      },
      "source": [
        "training_images = np.array(training_images,np.float64)*(1/255)\n",
        "test_images = np.array(test_images,np.float64)*(1/255)"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wa_0_SONaHjX"
      },
      "source": [
        "Flatten original image --> suitable for output of the network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_EsPGbfoaHjY"
      },
      "source": [
        "x_train = np.reshape(training_images,(training_images.shape[0],m*n))\n",
        "test_images = np.reshape(test_images,(test_images.shape[0],m*n))\n",
        "X = np.append(x_train,test_images,0)\n",
        "Y = np.append(training_labels,test_labels)"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MM4og-26aNt4"
      },
      "source": [
        "##Generate Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hy1qgV5kYtD8"
      },
      "source": [
        "def generate_model(layers_number,layers_nodenum,dropout,optimizer,loss,accuracy):\n",
        "  layers = []\n",
        "  layers.append(tf.keras.layers.Flatten())\n",
        "  for i in range(layers_number):\n",
        "    layers.append(tf.keras.layers.Dense(layers_nodenum[i],activation=tf.nn.relu))\n",
        "    layers.append(tf.keras.layers.Dropout(dropout[i]))\n",
        "  layers.append(tf.keras.layers.Dense(10,activation=tf.nn.softmax))\n",
        "  model = tf.keras.models.Sequential(layers)\n",
        "  model.compile(optimizer=optimizer, loss=loss, metrics=[accuracy])\n",
        "  model.build((None,m*n))\n",
        "  model.summary()\n",
        "  return model\n"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5CK6-kZsZC0A"
      },
      "source": [
        "def k_fold_train_test(X, Y, k_fold, model,):\n",
        "  model_name = model.__class__.__name__\n",
        "  accuracies = cross_val_score(model, X, Y, scoring = 'accuracy', cv= k_fold)\n",
        "  # result = []\n",
        "  # for fold_index, accuracy in enumerate(accuracies):\n",
        "  #   result.append((model_name, fold_index, accuracy))\n",
        "  print('Mean accuracy of the model in ' + str(k_fold) + ' fold is: ', np.average(accuracies, axis=0))\n",
        "  return accuracies"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VT7YRbRzYQ4Z",
        "outputId": "7e70cd65-67ac-40ad-f87a-ef2b6b150e4a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 814
        }
      },
      "source": [
        "model = generate_model(layers_number=2,\n",
        "                       layers_nodenum=[20,30],\n",
        "                       dropout=[0,0.1],\n",
        "                       optimizer='adam',\n",
        "                       loss='sparse_categorical_crossentropy',\n",
        "                       accuracy='accuracy')\n",
        "# accuracies = k_fold_train_test(X,Y,11,model)"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_8 (Flatten)          (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_29 (Dense)             (None, 20)                15700     \n",
            "_________________________________________________________________\n",
            "dropout_21 (Dropout)         (None, 20)                0         \n",
            "_________________________________________________________________\n",
            "dense_30 (Dense)             (None, 30)                630       \n",
            "_________________________________________________________________\n",
            "dropout_22 (Dropout)         (None, 30)                0         \n",
            "_________________________________________________________________\n",
            "dense_31 (Dense)             (None, 10)                310       \n",
            "=================================================================\n",
            "Total params: 16,640\n",
            "Trainable params: 16,640\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mEmpty\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    826\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 827\u001b[0;31m                 \u001b[0mtasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ready_batches\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    828\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEmpty\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    160\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_qsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mEmpty\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-78-9116471b3472>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m                        \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sparse_categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                        accuracy='accuracy')\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0maccuracies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mk_fold_train_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-76-8995aade6707>\u001b[0m in \u001b[0;36mk_fold_train_test\u001b[0;34m(X, Y, k_fold, model)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mk_fold_train_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk_fold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0maccuracies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mk_fold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m   \u001b[0;31m# result = []\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;31m# for fold_index, accuracy in enumerate(accuracies):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    388\u001b[0m                                 \u001b[0mfit_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m                                 \u001b[0mpre_dispatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 390\u001b[0;31m                                 error_score=error_score)\n\u001b[0m\u001b[1;32m    391\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    234\u001b[0m             \u001b[0mreturn_times\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_estimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_estimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m             error_score=error_score)\n\u001b[0;32m--> 236\u001b[0;31m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m     \u001b[0mzipped_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1046\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1047\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1048\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1049\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1050\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    836\u001b[0m                 \u001b[0mbig_batch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    837\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 838\u001b[0;31m                 \u001b[0mislice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mislice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbig_batch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    839\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mislice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    234\u001b[0m             \u001b[0mreturn_times\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_estimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_estimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m             error_score=error_score)\n\u001b[0;32m--> 236\u001b[0;31m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m     \u001b[0mzipped_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mclone\u001b[0;34m(estimator, safe)\u001b[0m\n\u001b[1;32m     65\u001b[0m                             \u001b[0;34m\"it does not seem to be a scikit-learn estimator \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m                             \u001b[0;34m\"as it does not implement a 'get_params' methods.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m                             % (repr(estimator), type(estimator)))\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0mklass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0mnew_object_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Cannot clone object '<tensorflow.python.keras.engine.sequential.Sequential object at 0x7fe2a6438f60>' (type <class 'tensorflow.python.keras.engine.sequential.Sequential'>): it does not seem to be a scikit-learn estimator as it does not implement a 'get_params' methods."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iLbOIwajpMQ4"
      },
      "source": [
        "#PART5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5u60272Q-IG5"
      },
      "source": [
        "##imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n5hYMfliqPnT"
      },
      "source": [
        "import tensorflow as tf\n",
        "from os import path, getcwd, chdir\n",
        "import cv2\n",
        "from skimage.util import random_noise\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from scipy import spatial\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mYnqhsleqMBd"
      },
      "source": [
        "## load dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zR18wvxoqIeu"
      },
      "source": [
        "load mnist dataset "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_eed9kzdpLhl"
      },
      "source": [
        "path = f\"{getcwd()}/mnist.npz\""
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9KdIqE9Fq1rC"
      },
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data(path=path)\n",
        "training_images = training_images.reshape(60000,28,28)\n",
        "test_images = test_images.reshape(10000,28,28)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SmMf79RDz0ml",
        "outputId": "9ed2cfd6-e07b-4c2e-82f2-de58a38ef0ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "m, n = training_images[0].shape[0], training_images[0].shape[1]\n",
        "print('The image is ({0}*{1})'.format(m,n))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The image is (28*28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bArV3ziG77mX"
      },
      "source": [
        "##Preprocess Data and generate train,validation,test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B2iH76eT0yg1"
      },
      "source": [
        "Normalize images --> map value into (0,1)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKk-v34vyqRr"
      },
      "source": [
        "training_images = np.array(training_images,np.float64)*(1/255)\n",
        "test_images = np.array(test_images,np.float64)*(1/255)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1uM9gCkZ0iny"
      },
      "source": [
        "Flatten original image --> suitable for output of the network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_hyog7sv0dIJ"
      },
      "source": [
        "x_train = np.reshape(training_images,(training_images.shape[0],m*n))\n",
        "test_images = np.reshape(test_images,(test_images.shape[0],m*n))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kb6Nzqop3zeN"
      },
      "source": [
        "x_test, x_val, y_test, y_val = train_test_split(test_images, test_labels, test_size=0.4, random_state=42)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FS45sc-j1CP8",
        "outputId": "717f50a6-98a9-4b0f-a287-a5546bff723f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "print('train shape:',x_train.shape[0])\n",
        "print('train shape:',x_val.shape[0])\n",
        "print('test shape:',x_test.shape[0])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train shape: 60000\n",
            "train shape: 4000\n",
            "test shape: 6000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BW2WLNjzwuSN"
      },
      "source": [
        "##Add noise"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qUpjR6qUq30E"
      },
      "source": [
        "def make_noisydata(data,model,var,portion):\n",
        "  noisy_data = np.empty(data.shape)\n",
        "  if model == 'gaussian':\n",
        "    for i in range(data.shape[0]):\n",
        "      noisy_data[i] = random_noise(data[i],model,var = var)\n",
        "  elif model == 's&p':\n",
        "    for i in range(data.shape[0]):\n",
        "      noisy_data[i] = random_noise(data[i],model,amount=portion)\n",
        "  return noisy_data"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Du5KsQKY5Tgm"
      },
      "source": [
        "def add_noise(model,var,portion):\n",
        "  noisy_train = make_noisydata(x_train,model,var,portion)\n",
        "  noisy_val = make_noisydata(x_val,model,var,portion)\n",
        "  noisy_test = make_noisydata(x_test,model,var,portion)\n",
        "  return noisy_train, noisy_val,noisy_test"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LvL5i62t8_Uc"
      },
      "source": [
        "##Generate Model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JW6j67xiomRg"
      },
      "source": [
        "def generate_model(layers_number,layers_nodenum,dropout,optimizer,loss,accuracy):\n",
        "  layers = []\n",
        "  layers.append(tf.keras.layers.Flatten())\n",
        "  for i in range(layers_number):\n",
        "    layers.append(tf.keras.layers.Dense(layers_nodenum[i],activation=tf.nn.relu))\n",
        "    layers.append(tf.keras.layers.Dropout(dropout[i]))\n",
        "  layers.append(tf.keras.layers.Dense(m*n,activation=tf.nn.softmax))\n",
        "  model = tf.keras.models.Sequential(layers)\n",
        "  model.compile(optimizer=optimizer, loss=loss, metrics=[accuracy])\n",
        "  model.build((None,m*n))\n",
        "  model.summary()\n",
        "  return model\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Oktja194o0i"
      },
      "source": [
        "def RemoveNoise(model_info,epochs,train=True):\n",
        "  model = generate_model(model_info['layer_number'],model_info['layer_nodenum'],model_info['dropout_postion'],model_info['optimizer'],model_info['loss'],model_info['accuracy'])\n",
        "  mcp_save = tf.keras.callbacks.ModelCheckpoint(model_info['best_model_path'], save_best_only=True, monitor='val_cosine_similarity', mode='max')\n",
        "  if train:\n",
        "    history = model.fit(n_train,x_train,validation_data= (n_val,x_val), epochs=epochs,callbacks=[mcp_save] )\n",
        "  model.load_weights(model_info['best_model_path'])\n",
        "  print('best accurasy on train data is:',model.evaluate(n_train, x_train)[1],)\n",
        "  print('best accurasy on validation data is:',model.evaluate(n_val, x_val)[1],)\n",
        "  print('best accurasy on test data is:',model.evaluate(n_test, x_test)[1],)\n",
        "  return model"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SwJZkBdIHkGq"
      },
      "source": [
        "def checktestsample(model,sample):\n",
        "  y_pred = model.predict(np.array([n_test[sample]]))\n",
        "  similarity = 1 - spatial.distance.cosine(y_pred[0], x_test[sample])\n",
        "  y_pred0 = np.reshape(y_pred[0],(m,n))\n",
        "  image_list = []\n",
        "  image_list.append([x_test[sample].reshape((m,n)), 'Original Test Image', 'img'])\n",
        "  image_list.append([n_test[sample].reshape((m,n)), 'Noisy Test Image', 'img'])\n",
        "  image_list.append([y_pred0, 'Predicted Image', 'img'])\n",
        "  print(\"cos similarity between desired and predicted is:%{0}\".format(similarity))\n",
        "  plotter(image_list,1,3 ,True,10,10)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dPVe1jbGX734"
      },
      "source": [
        "##RUN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ovDnlLGJzISJ",
        "outputId": "35f6f59d-f363-4b6e-8a90-e01501708bda",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 550
        }
      },
      "source": [
        "noise_info ={\n",
        "    'model': 'gaussian',\n",
        "    'var': 0.5,\n",
        "    'portion': 0.2\n",
        "}\n",
        "model_info={\n",
        "    'layer_number':3,\n",
        "    'layer_nodenum' : [254,128,32],\n",
        "    'dropout_postion': [0,0.1,0],\n",
        "    'optimizer': tf.keras.optimizers.Adam(),\n",
        "    'loss': tf.keras.losses.CosineSimilarity(),\n",
        "    'accuracy':tf.keras.metrics.CosineSimilarity(name='cosine_similarity'),\n",
        "    'best_model_path':'.mdl_wts.hdf5'\n",
        "}\n",
        "n_train, n_val,n_test = add_noise(noise_info['model'],noise_info['var'],noise_info['portion'])\n",
        "best_model = RemoveNoise(model_info,epochs=35,train=False)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_4 (Flatten)          (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 254)               199390    \n",
            "_________________________________________________________________\n",
            "dropout_12 (Dropout)         (None, 254)               0         \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 128)               32640     \n",
            "_________________________________________________________________\n",
            "dropout_13 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_18 (Dense)             (None, 32)                4128      \n",
            "_________________________________________________________________\n",
            "dropout_14 (Dropout)         (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_19 (Dense)             (None, 784)               25872     \n",
            "=================================================================\n",
            "Total params: 262,030\n",
            "Trainable params: 262,030\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: -0.8265 - cosine_similarity: 0.8265\n",
            "best accurasy on train data is: 0.8265052437782288\n",
            "125/125 [==============================] - 0s 1ms/step - loss: -0.8302 - cosine_similarity: 0.8302\n",
            "best accurasy on validation data is: 0.830161988735199\n",
            "188/188 [==============================] - 0s 2ms/step - loss: -0.8325 - cosine_similarity: 0.8325\n",
            "best accurasy on test data is: 0.8324647545814514\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U9sn2Onv2yQ3",
        "outputId": "7b377a4a-86f7-4d48-aaba-286d49396fd8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "checktestsample(best_model,26)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cos similarity between desired and predicted is:%0.7658917471877816\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 3 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}